name: Check links of the site
on:
  schedule:
    - cron: "0 5 * * 3" # every wednesday at 5:00 UTC
  workflow_dispatch:
    # This configuration is commented out because we don't want to send notifications to Slack (see later in this file)
    # inputs:
    #   slack-notifications:
    #     type: boolean
    #     description: "If checked, send slack notifications when errors occur"
    #     default: false

jobs:
  check_links:
    runs-on: ubuntu-22.04
    steps:
      - uses: actions/checkout@v6 # access to the local action
      - name: Build Setup
        uses: ./.github/actions/build-setup
      - name: Build site
        # '>' Replace newlines with spaces (folded)
        # '-' No newline at end (strip)
        run: >-
          ./build-preview-dev.bash
          --hide-edit-page-links true
          --force-production-navbar true
          --type links-check
          --ignore-errors true
          --fail-on-warning false
          --use-multi-repositories
          --component-with-branches bcd:3.6,4.0
          --component-with-branches bpi:main
          --component-with-branches bonita:archives,2023.2,2024.1,2024.2,2024.3,2025.1,2025.2
          --component-with-branches central:1.0
          --component-with-branches cloud:master
          --component-with-branches labs:master
          --component-with-branches test-toolkit:1.0,2.0,3.0,3.1
      - name: List the content of the generated site
        uses: ./.github/actions/log-built-site-details
      - name: Remove pages that we don't want to check
        run: |
          node scripts/remove-generated-dependencies-pages.cjs
      - name: Upload site used for links check
        uses: actions/upload-artifact@v5
        with:
          name: check-links-site-${{github.sha}}
          path: build/site
      - name: Install htmltest
        run: |
          echo "Installing htmltest"
          curl https://htmltest.wjdp.uk | bash -s -- -b scripts/htmltest v0.17.0
          echo "Installation done"
          ./scripts/htmltest/htmltest --version

        # Retry the link check multiple times to reduce false positives from temporary network issues.
        # Each retry uses cache from previous runs to minimize external requests and speed up subsequent checks.
        # Mitigates HTTP 429 (rate limit) errors from GitHub by reusing cached results and retrying until success.
      - name: Check links
        id: check_links
        uses: nick-fields/retry@v3
        with:
          timeout_minutes: 15 # the first analysis takes around 7 minutes
          max_attempts: 5
          # use a workaround as there is no working directory input in the retry action, see https://github.com/nick-fields/retry/issues/89
          command: |
            cd scripts/htmltest
            ./htmltest -c ./htmltest_bonita-documentation-site.yml ../../build/site

      - name: Upload links analysis
        if: always()
        uses: actions/upload-artifact@v5
        with:
          name: check-links-analysis-${{ github.sha }}
          path: scripts/htmltest/config


      # This step is commented out because we don't want to send notifications to Slack for now, we can uncomment it later, when all errors will be fixed.
      # For now, we will monitor the workflow result each week manually.
      # - name: Send message to Slack channel
      #   if: failure() && (github.event_name == 'schedule' || (github.event_name == 'workflow_dispatch' && github.event.inputs.slack-notifications == 'true') )
      #   uses: bonitasoft/notify-slack-action@v1
      #   with:
      #     keeper-secret-config: ${{ secrets.KSM_CONFIG }}
      #     channel-id: ${{ vars.RD_PLATFORM_SLACK_CHANNEL_ID }}
      #     message: |
      #       :fire: The documentation contains broken links! :fire:
      #       @channel *We need someone*!
      #       - Add a :fire_extinguisher:if you take the action to resolve the conflicts (only one person is required)
      #       - Add a :sweat_drops: when itâ€™s done (and eventually a :party_parrot:)
      #       Run the logs of the GitHub workflow run or download the check links analysis to find the pages including the broken links.
      #       Then, create a Pull Request in the related content repository to fix the broken links (do the fix on the oldest version including the problem).
